{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "In this notebook, I implement a Hidden Markov Model (HMM) with Gaussian Response variables based on text and code examples of Zucchini and MacDonald [1].\n",
    "\n",
    "HMMs are characterized by the following [2]:\n",
    "\n",
    "1. They try to infer **hidden** or **latent** states from discrete or continuous time-series data. Consider the image below. On the x-axis we have time, so this is a time-series dataset. On the y-axis we have four sleep stages (light, deep, REM sleep and wakefulness). These are the latent stages. My fitbit attempts to extract these stages based on my movement and heart rate for each point in the time-series. This results in a sequence of latent states. For the image below, that would look something like this: (Awake, REM, REM, REM, ..., Deep, Deep, REM, Deep, Deep, Awake, ...) and so on.\n",
    "\n",
    "<img src=\"img/sleeeeeeping.PNG\" width=\"500\">\n",
    "\n",
    "2. They are **memoryless** models. When predicting the state at time point $t$, these models only look at the state at $t-1$ to infer the probability of transitioning into a next state. If the state at $t-1$ is REM, then what is the probability of observing the next state as REM, light, deep sleep or wakefulness? This is also called the *Markov assumption*.\n",
    "\n",
    "3. Each state has its own **component distribution**, and the joint distribution of these component distribution is a **mixture distribution**. All this means is that we think that REM sleep, light sleep, deep sleep and wakefulness have different distributions when we consider movement and heart rate. This is easy enough to believe if you think about these variables; a person who is awake typically has a heart rate between 60-100 BPM, whereas a person in deep sleep has a heart rate of 50-60 BPM. If we believed these variables to be normally distributed, then we could model the heart rate component distributions using the means 75 for wakefulness and 55 for deep sleep. Depending on which heart rate we observe at each time step, we can compute the probability of seeing that observation for each of the component distributions.\n",
    "\n",
    "Note that the mixture distribution in (3) is not independent. In independent mixture distributions (e.g. multivariate normal distribution) the observations are drawn without conditioning on a third variable (for example a sleep state at a specific point in time). In our case, however, the observations are drawn based on the previous state, and these probabilities are different for each state. For example, it is not likely that you will go from wakefulness into REM sleep immediately, so the probability of seeing this state after observing a wakeful state is low. Conversely, it is very likely that you will go from light sleep to REM, so the probability associated with this transition is much higher.\n",
    "\n",
    "### Notation\n",
    "\n",
    "I use the following notation in this notebook [1]. \n",
    "\n",
    "* For a time-series sequence of length $T$, let the observed outcome data (e.g. movement/heart rate) be denoted by $X_{1:T} := (X_1, X_2, \\dots, X_T)$.\n",
    "* Let $m$ denote the number of components in the HMM and let $C_t = i, i \\in \\{1, 2, \\dots, m\\}$ denote the component of the HMM at time $t$. \n",
    "* The distribution $X_t$ of the observed data is considered to be dependent on the state $C_t$, so that we can write $p_i(X_t) := p(X_t | C_t = i)$.\n",
    "* The marginal distribution (collapsed over all the states) is given by the mixture distribution $p(X_t) = \\sum_{i=1}^m \\delta_i p_i(X_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating data for Gaussian response distributions\n",
    "\n",
    "### Simulating a hidden sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of components \n",
    "k = 2\n",
    "# Timesteps t\n",
    "T = 100\n",
    "# Set seed\n",
    "np.random.seed(563)\n",
    "# Transition matrix\n",
    "g = np.array([[0.33, 0.67],\n",
    "              [0.89, 0.11]])\n",
    "# Initial states\n",
    "pi = np.array([0.71, 0.29])\n",
    "# mu / sd of the states\n",
    "mu = np.array([7,15])\n",
    "sd = np.array([2,4])\n",
    "# Draw from one of the states with probability pi_i\n",
    "np.random.multinomial(1, pi)\n",
    "# Generate sequence\n",
    "seq = np.zeros((T, 1), dtype = np.int32)\n",
    "for t in range(T):\n",
    "    if t == 0:\n",
    "        seq[t,:] = int(np.nonzero(np.random.multinomial(1, pi))[0])\n",
    "    else:\n",
    "        seq[t,:] = int(np.nonzero(np.random.multinomial(1, np.dot(pi, np.linalg.matrix_power(g, t))))[0])\n",
    "        \n",
    "# Squeeze output\n",
    "seq = seq.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating observed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate\n",
    "obs = np.zeros(T, dtype = np.float32)\n",
    "# Set seed\n",
    "np.random.seed(886)\n",
    "# Populate\n",
    "for i in range(T):\n",
    "    # Get state\n",
    "    state = seq[i]\n",
    "    # Draw from normal distribution\n",
    "    obs[i] = np.round(np.random.normal(mu[state], sd[state]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/.local/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6983551320>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot observed data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.distplot(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the state sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward algorithm\n",
    "from scipy.stats import norm\n",
    "\n",
    "# We use the initial probabilities pi\n",
    "# NOTE: we shouldn't really know these ...\n",
    "\n",
    "# Initialize alpha using the initial distribution\n",
    "alpha = pi\n",
    "# Initialize states to 0\n",
    "states = np.zeros(T, dtype = np.int32)\n",
    "# For each observation and timestep t, compute the state using the forward algorithm\n",
    "for t, x in enumerate(obs):\n",
    "    # Compute probabilities for x at timestep t\n",
    "    # Note that we are not assuming stationarity because we have alpha_1 = pi * P \n",
    "    #  at t == 1\n",
    "    # Note that we are using population values mu and sd here\n",
    "    p = norm.pdf(x, mu, sd)\n",
    "    # Convert to diagonal matrix\n",
    "    P = np.diag(p)\n",
    "    # Form the matrix B\n",
    "    B = np.dot(g, P)\n",
    "    # Update alpha\n",
    "    alpha = np.dot(alpha, B)\n",
    "    # Add state\n",
    "    states[t] = np.argmax(alpha)\n",
    "    # At the last step, dot with 1' to get the likelihood\n",
    "    if t == (T-1):\n",
    "        L = np.dot(alpha, np.ones((k, 1), dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 observations ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual\n",
       "0          0       0\n",
       "1          0       0\n",
       "2          0       0\n",
       "3          0       0\n",
       "4          1       0\n",
       "5          1       1\n",
       "6          0       0\n",
       "7          1       1\n",
       "8          0       0\n",
       "9          1       1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack predicted and actual states column-wise\n",
    "import pandas as pd\n",
    "seqs = np.vstack((states,seq)).T\n",
    "# Cast to data frame\n",
    "print(\"First 10 observations ...\")\n",
    "pd.DataFrame(seqs, columns = [\"predicted\", \"actual\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: [9.83704503e-129]\n",
      "Alphas at time T: [5.34333284e-138 9.83704502e-129]\n"
     ]
    }
   ],
   "source": [
    "# Print likelihood and alphas\n",
    "print(\"Likelihood: {}\".format(L))\n",
    "print(\"Alphas at time T: {}\".format(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above implementation of the forward algorithm, clearly we are running into the issue of underflow. The values for the alphas are getting very small, and we need to start using some computational tricks to make sure we can handle longer sequences. See also chapt. 3.2 in Zucchini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward algorithm\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Initialize alphas using the initial distribution\n",
    "# scale the distribution by the sum of the alphas to prevent underflow\n",
    "ones = np.ones((k, 1), dtype = np.int32)\n",
    "phi = pi / np.dot(pi, ones) # ==> this is just scaling by 1 \n",
    "# Initialize states to 0\n",
    "states = np.zeros(T, dtype = np.int32)\n",
    "# Initialize log-likelihood to 0\n",
    "L = 0\n",
    "# For each observation, compute the state using the forward algorithm\n",
    "for t, x in enumerate(obs):\n",
    "    # Compute probabilities for x at timestep t\n",
    "    p = norm.pdf(x, mu, sd)\n",
    "    # Convert to diagonal matrix\n",
    "    P = np.diag(p)\n",
    "    # Form the matrix B\n",
    "    B = np.dot(g, P)\n",
    "    # Create the vector v as the product of scaled alphas and B\n",
    "    v = np.dot(phi, B)\n",
    "    # Create the scalar u as the sum of the scaled alphas\n",
    "    u = np.dot(v, ones)\n",
    "    # Add to log-likelihood\n",
    "    L += np.log(u)\n",
    "    # Scale vector by the sum of v to create new phi\n",
    "    phi = v / u\n",
    "    # Add state\n",
    "    states[t] = np.argmax(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 observations ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual\n",
       "0          0       0\n",
       "1          0       0\n",
       "2          0       0\n",
       "3          0       0\n",
       "4          1       0\n",
       "5          1       1\n",
       "6          0       0\n",
       "7          1       1\n",
       "8          0       0\n",
       "9          1       1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack predicted and actual states column-wise\n",
    "import pandas as pd\n",
    "seqs = np.vstack((states,seq)).T\n",
    "# Cast to data frame\n",
    "print(\"First 10 observations ...\")\n",
    "pd.DataFrame(seqs, columns = [\"predicted\", \"actual\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood: [-294.74732163]\n",
      "Phi at time T: [5.43184749e-10 9.99999999e-01]\n"
     ]
    }
   ],
   "source": [
    "# Print likelihood and alphas\n",
    "print(\"Log-Likelihood: {}\".format(L))\n",
    "print(\"Phi at time T: {}\".format(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_forward(X: np.array, pi: np.array, gamma: np.array, \n",
    "                mu: np.array, sd: np.array, return_states = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the forward step of an HMM\n",
    "    \n",
    "    :param X: n x 1 numpy array containing the observed data\n",
    "    :param pi: m x 1 numpy array containing initial values\n",
    "    :param gamma: m x m numpy array containing transition probabilities\n",
    "    :param mu: m x 1 numpy array containing means of component distributions\n",
    "    :param sd: m x 1 numpy array containing sds of component distributions\n",
    "    :param return_states: boolean. If True, then the state sequence is returned\n",
    "    \n",
    "    :return: Log-Likelihood and, if desired, the state sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    # For dimensions\n",
    "    m = mu.shape[0]\n",
    "    T = X.shape[0]\n",
    "    \n",
    "    # Initialize alphas using the initial distribution\n",
    "    # scale the distribution by the sum of the alphas to prevent underflow\n",
    "    ones = np.ones((m, 1), dtype = np.int32)\n",
    "    phi = pi \n",
    "    # Initialize states to 0\n",
    "    if return_states: states = np.zeros(T, dtype = np.int32)\n",
    "    # Initialize log-likelihood to 0\n",
    "    L = 0\n",
    "    # For each observation, compute the state using the forward algorithm\n",
    "    for t, x in enumerate(X):\n",
    "        # Compute probabilities for x at timestep t\n",
    "        p = norm.pdf(x, mu, sd)\n",
    "        # Convert to diagonal matrix\n",
    "        P = np.diag(p)\n",
    "        # Form the matrix B\n",
    "        B = np.dot(gamma, P)\n",
    "        # Create the vector v as the product of scaled alphas and B\n",
    "        v = np.dot(phi, B)\n",
    "        # Create the scalar u as the sum of the scaled alphas\n",
    "        u = np.dot(v, ones)\n",
    "        # Add to log-likelihood\n",
    "        L += np.log(u)\n",
    "        # Scale vector by the sum of v to create new phi\n",
    "        phi = v / u\n",
    "        # Add state\n",
    "        if return_states: states[t] = np.argmax(phi)\n",
    "        \n",
    "    # Return\n",
    "    if return_states:\n",
    "        return((L, states))\n",
    "    else:\n",
    "        return(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization using an unconstrained optimizer\n",
    "\n",
    "### Dealing with constraints\n",
    "\n",
    "For the HMM with normal distribution we have no real constraints on the parameters $\\mu_1, \\mu_2, \\sigma^2_1, \\sigma^2_2$ since they are continuous and can take on any value. However, we have a constraint on the transition probability matrix $\\pmb{\\Gamma}$ because its rows must sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tpm(gamma: np.array) -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    Transform the transition probability matrix gamma using the function g(x) = exp(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply transformation of gamma\n",
    "    # NOTE: have to reshape this as a column vector to make it compatible with R implementation\n",
    "    tgamma = np.log(gamma / np.diag(gamma).reshape((gamma.shape[0],1)))\n",
    "    # Retrieve off-diagonal elements\n",
    "    # NOTE: have to reverse the nonzero elements to make it compatible with R implementation\n",
    "    idx_tau = np.nonzero(tgamma)[::-1]\n",
    "    # Retrieve nonzero elements\n",
    "    tgamma_flat = tgamma[idx_tau]\n",
    "    # Return values of transformation and indices\n",
    "    return({\"tgamma\": tgamma_flat, \"tgamma_idx\": idx_tau})\n",
    "\n",
    "def transform_tgamma(tgamma: dict) -> np.array:\n",
    "    \n",
    "    \"\"\"\n",
    "    Transform the transformed values of gamma back to probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get values from dict\n",
    "    tgamma, tgamma_idx = tgamma.values()\n",
    "    # Identity matrix\n",
    "    z = np.eye(tgamma_idx[0].shape[0])\n",
    "    # Fill off-diagonal elements\n",
    "    z[tgamma_idx] = np.exp(tgamma)\n",
    "    # Scale\n",
    "    z /= np.sum(z, axis=1).reshape((z.shape[0], 1))\n",
    "    # Solve for delta (initial values)\n",
    "    delta = np.linalg.solve((np.eye(z.shape[0]) - z + 1).T, np.ones(z.shape[0]))\n",
    "    # Return\n",
    "    return((z, delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33 0.67]\n",
      " [0.89 0.11]]\n",
      "[0.57051282 0.42948718]\n"
     ]
    }
   ],
   "source": [
    "# Transform the transition probability matrix\n",
    "a = transform_tpm(g)\n",
    "# Transform back and solve for delta\n",
    "gam, delta = transform_tgamma(a)\n",
    "# Print\n",
    "print(gam)\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting values\n",
    "\n",
    "To assign starting values for the parameters, we can do the following:\n",
    "\n",
    "1. For means, we can divide the observations into $k$ subsets using quartiles/quantiles and take the mean of the subsets.\n",
    "2. For variances, we can take the variance of the $k$ subsets.\n",
    "3. For initial transition probabilities, we can initialize the matrix $\\pmb{\\Gamma}$ using a uniform distribution with small values (e.g. 0.01 - 0.05) or initialize all values using the same, small value (e.g. 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values \n",
    "gamma = np.array([[0.99, 0.01],\n",
    "                  [0.01, 0.99]])\n",
    "# Split observed data at median\n",
    "gr1 = obs[obs < np.median(obs)]\n",
    "gr2 = obs[obs >= np.median(obs)]\n",
    "# Construct means / variances\n",
    "mu = np.array([np.mean(gr1), np.mean(gr2)])\n",
    "sd = np.array([np.sqrt(np.var(gr1)), np.sqrt(np.mean(gr2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.59511985, -4.59511985,  6.21368217, 13.91755962,  1.38666451,\n",
       "        3.73062468])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimize function only takes a single array, so we need to add all parameters to a single array\n",
    "tgamma, tgamma_idx = transform_tpm(gamma).values()\n",
    "# Concatenate values to flat array\n",
    "x0 = np.concatenate([tgamma, mu, sd])\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def HMM(parameters: np.array, *args: tuple) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Given an array of parameters, compute the log-likelihood of the HMM\n",
    "    \n",
    "    :param parameters: parameters passed to the model. This is a single (flat)\n",
    "                        numpy array whose valuese correspond to the following \n",
    "                        parameters:\n",
    "                         (1) indices 0:(m*(m-1)) ==> transformed values of the \n",
    "                              transition matrix\n",
    "                         (2) indices (m*(m-1)):[(m*(m-1))+m] ==> means of the \n",
    "                              component distributions\n",
    "                         (3) indices [(m*(m-1))+m]:[(m*(m-1))+2*m] ==> variances\n",
    "                              of the component distributions\n",
    "    :param *args: additional parameters passed to the function:\n",
    "                         (1) args[0] ==> number of components\n",
    "                         (2) args[1] ==> tuple of numpy arrays used to transform\n",
    "                                          the transformed gamma values back to\n",
    "                                          their original form\n",
    "                                          \n",
    "    :return: Log-Likelihood of the model given the parameters\n",
    "                                          \n",
    "    :seealso: functions transform_tpm() and transform_tgamma() above\n",
    "    \n",
    "    :seealso: Zucchini, W., MacDonald, I. L., & Langrock, R. (2017). Hidden Markov \n",
    "                             models for time series: an introduction using R. \n",
    "                             Chapman and Hall/CRC. Chapters 2-3\n",
    "    \"\"\"\n",
    "    \n",
    "    # Args is the size of the 2x2 gamma matrix and the tgamma idices to backtransform to gamma\n",
    "    m = args[0]\n",
    "    tgamma_idx = args[1]\n",
    "    \n",
    "    # Unroll parameters\n",
    "    tgamma = parameters[:(m*(m-1))]\n",
    "    mu = parameters[(m*(m-1)):(m*(m-1)+m)]\n",
    "    sd = parameters[(m*(m-1)+m):(m*(m-1)+2*m)]\n",
    "    \n",
    "    # Transform working parameters to natural parameters \n",
    "    # And solve for delta (initial values)\n",
    "    gamma, pi = transform_tgamma({\"tgamma\": tgamma, \"tgamma_idx\": tgamma_idx})\n",
    "    \n",
    "    # Compute LL\n",
    "    L = HMM_forward(obs, pi, gamma, mu, sd, return_states = False)\n",
    "    \n",
    "    # Return log-likelihood\n",
    "    return( -1 * L[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optimize function from scipy\n",
    "res = minimize(HMM, x0, args = (2, tgamma_idx), method = \"L-BFGS-B\",\n",
    "               options = {'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform gamma and pi\n",
    "gamma, pi = transform_tgamma({\"tgamma\":res.x[:2], \"tgamma_idx\":tgamma_idx})\n",
    "# Construct mu, sd\n",
    "mu = res.x[2:4]\n",
    "sd = res.x[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute state sequences\n",
    "_, states_pred = HMM_forward(obs, pi, gamma, mu, sd, return_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 observations ...\n",
      "Steps correct: 95.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual\n",
       "0          0       0\n",
       "1          0       0\n",
       "2          0       0\n",
       "3          0       0\n",
       "4          1       0\n",
       "5          1       1\n",
       "6          0       0\n",
       "7          1       1\n",
       "8          0       0\n",
       "9          1       1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack predicted and actual states column-wise\n",
    "import pandas as pd\n",
    "seqs = np.vstack((states_pred,seq)).T\n",
    "# Cast to data frame\n",
    "print(\"First 10 observations ...\")\n",
    "print(\"Steps correct: {}%\".format(np.round(sum(states_pred == seq) / len(seq),4) * 100))\n",
    "pd.DataFrame(seqs, columns = [\"predicted\", \"actual\"]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization using Expectation-Maximization (EM) \n",
    "\n",
    "The function below is a general, recursive function that can be used to compute the likelihood and state sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_EM(X: np.array, phi: np.array, gamma: np.array, k: int, **kwargs) -> tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "    Use forward algorithm to compute the state sequence and Log-Likelihood\n",
    "    \n",
    "    :param X: Observed data\n",
    "    :param phi: Initial distribution\n",
    "    :param gamma: Transition Probability Matrix \n",
    "    :param k: Number of hidden states\n",
    "    \n",
    "    :return: tuple containing \n",
    "        (1) state sequence as T-dimensional array\n",
    "        (2) Log-Likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize alphas using the initial distribution\n",
    "    # scale the distribution by the sum of the alphas to prevent underflow\n",
    "    ones = np.ones((k, 1), dtype = np.int32)\n",
    "    # If states not supplied, initialize them\n",
    "    if kwargs.get(\"states\") is None:\n",
    "        # Initialize states to 0\n",
    "        states = np.zeros(X.shape[0], dtype = np.int32)\n",
    "    else:\n",
    "        states = kwargs[\"states\"]\n",
    "    # Initialize log-likelihood to 0 if not passed\n",
    "    if kwargs.get(\"L\") is None:\n",
    "        L = kwargs[\"L\"]\n",
    "    else:\n",
    "        L = 0\n",
    "        \n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Zucchini, W., MacDonald, I. L., & Langrock, R. (2017). Hidden Markov models for time series: an introduction using R. Chapman and Hall/CRC. <br>\n",
    "[2] Visser, I. (2011). Seven things to remember about hidden Markov models: A tutorial on Markovian models for time series. Journal of Mathematical Psychology, 55(6), 403-415. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "HMM",
   "language": "python",
   "name": "hmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
